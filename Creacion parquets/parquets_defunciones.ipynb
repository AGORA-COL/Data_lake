{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a990c48-c253-43e9-bf16-4359daefd9bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/26 18:43:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crear una sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"CSVtoParquet\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97284b19-9533-4db8-af9c-666f8834f7c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Leer el primer archivo CSV\n",
    "df1 = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"encoding\", \"latin1\") \\\n",
    "    .load(\"/rawdata/vitales/defunciones/ConsultarDefunciones_2008_a_2016.txt\")\n",
    "\n",
    "# Leer el segundo archivo CSV\n",
    "df2 = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"encoding\", \"latin1\") \\\n",
    "    .load(\"/rawdata/vitales/defunciones/ConsultarDefunciones_2017_a_2023.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d3d68d2-9cf1-4a29-839d-baa1d5515158",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configurar tamaño objetivo de los archivos Parquet (aproximadamente 7MB)\n",
    "target_file_size_mb = 7\n",
    "target_file_size_bytes = target_file_size_mb * 1024 * 1024\n",
    "\n",
    "# Definir una función para guardar DataFrame como Parquet con tamaño objetivo\n",
    "def save_as_parquet(df, output_dir, target_size):\n",
    "    # Repartir el DataFrame para aproximar el tamaño objetivo\n",
    "    df = df.repartition((df.count() * df.columns.__len__() * 8) // target_size)\n",
    "    # Escribir el DataFrame en el formato Parquet\n",
    "    df.write.mode(\"overwrite\").parquet(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83f6292e-11cf-4ee4-805c-d8b3cfcea00e",
     "showTitle": false,
     "title": ""
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Guardar el primer DataFrame como archivos Parquet en la carpeta especificada\n",
    "save_as_parquet(df1, \"/rawdata/vitales/defunciones/defunciones_parquet_2008_a_2016\", target_file_size_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Guardar el segundo DataFrame como archivos Parquet en la carpeta especificada\n",
    "save_as_parquet(df2, \"/rawdata/vitales/defunciones/defunciones_parquet_2017_a_2023\", target_file_size_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 18:47:26,822 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:28,163 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:29,537 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:31,478 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:33,254 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:34,666 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:35,971 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:37,342 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:39,216 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:40,573 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:41,917 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:43,326 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:46,993 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:48,361 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:49,733 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:51,123 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:53,072 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:54,724 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:56,103 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:57,491 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:47:58,843 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:00,222 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:01,547 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:02,934 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:04,314 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:05,727 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:07,167 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:08,494 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:09,835 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:11,222 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:12,612 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:13,962 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:15,340 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:16,674 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:18,003 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:19,388 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:20,750 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:22,082 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:23,452 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:24,817 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:26,616 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:28,002 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:29,342 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:30,733 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:33,634 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:35,287 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:36,641 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:38,013 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:39,412 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:40,755 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:42,432 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:43,844 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:45,194 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-06-26 18:48:46,556 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 18:48:48,454 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Función para renombrar archivos Parquet\n",
    "def rename_parquet_files(directory):\n",
    "    # Listar los archivos en el directorio\n",
    "    files = subprocess.check_output([\"hdfs\", \"dfs\", \"-ls\", directory]).decode(\"utf-8\").split(\"\\n\")\n",
    "    parquet_files = [line.split()[-1] for line in files if line.endswith(\".parquet\")]\n",
    "    \n",
    "    # Renombrar los archivos\n",
    "    for idx, file in enumerate(parquet_files):\n",
    "        new_name = f\"{directory}/part.{idx}.parquet\"\n",
    "        subprocess.call([\"hdfs\", \"dfs\", \"-mv\", file, new_name])\n",
    "\n",
    "# Renombrar los archivos en las carpetas especificadas\n",
    "rename_parquet_files(\"/rawdata/vitales/defunciones/defunciones_parquet_2008_a_2016\")\n",
    "rename_parquet_files(\"/rawdata/vitales/defunciones/defunciones_parquet_2017_a_2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e86e962d-5239-4c02-b5c2-b08df33099fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Detener la sesión de Spark\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "parquets_vacunascovid",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
